{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from skimage import io\n",
    "import random\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "print (tf.__version__)\n",
    "tf.config.experimental.list_physical_devices(device_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Updated/Processed/train\\COVID-19\\*\n"
     ]
    }
   ],
   "source": [
    "# path to your dataset\n",
    "Train_DATASET_PATH = './Updated/Processed/train'\n",
    "TEST_DATASET = './Updated/Processed/test'\n",
    "data_cls = ['COVID-19', 'NORMAL', 'Viral']\n",
    "\n",
    "# globbing example\n",
    "# help(glob)\n",
    "covid_path = os.path.join(Train_DATASET_PATH, data_cls[0], '*')\n",
    "print(covid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# specify image size and channels\n",
    "img_channels = 3\n",
    "img_rows = 256\n",
    "img_cols = 256\n",
    "\n",
    "# number of classes\n",
    "nb_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2799 images belonging to 3 classes.\n",
      "Found 699 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1,\n",
    "                             zoom_range=0.1,\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "training_set = datagen.flow_from_directory(\n",
    "        Train_DATASET_PATH,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "validation_set = datagen.flow_from_directory(\n",
    "    Train_DATASET_PATH,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# validtion_datagen = ImageDataGenerator()\n",
    "# validtion_set = validtion_datagen.flow_from_directory(\n",
    "#         './Image_3/validation',\n",
    "#         target_size=(224, 224),\n",
    "#         batch_size=32,shuffle=True,\n",
    "#         class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic way to create custom callback\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "# from tensorflow.keras import optimizers\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.vgg19 import VGG19\n",
    "# from tensorflow.keras.applications import ResNet101, DenseNet201 ,InceptionV3\n",
    "# from tensorflow.keras.layers import Input, Add, AveragePooling2D,  GlobalAveragePooling2D ,GlobalMaxPool2D\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# input_shape = (224,224,3)\n",
    "# densenet = tf.keras.applications.DenseNet121( include_top=False, weights=None, pooling='max',input_shape=input_shape )\n",
    "\n",
    "# x = densenet.output\n",
    "# predictions = Dense(3, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "# model = Model(inputs=densenet.inputs, outputs=predictions)\n",
    "# model.load_weights('./densenet121_weights_tf.h5',by_name=True, skip_mismatch=True)\n",
    "# #print (model.summary())\n",
    "# print (len(model.layers))\n",
    "\n",
    "# base_model =  DenseNet201(weights='imagenet', include_top=False ,input_shape=input_shape)\n",
    "# print (len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 24579     \n",
      "=================================================================\n",
      "Total params: 20,048,963\n",
      "Trainable params: 17,723,395\n",
      "Non-trainable params: 2,325,568\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 143s 2s/step - loss: 1.6364 - accuracy: 0.3793 - val_loss: 0.3777 - val_accuracy: 0.8884\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88839, saving model to models_img\\best_model.hdf5\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 137s 2s/step - loss: 0.4158 - accuracy: 0.8499 - val_loss: 0.3612 - val_accuracy: 0.8676\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.88839\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 141s 2s/step - loss: 0.2714 - accuracy: 0.8961 - val_loss: 0.1936 - val_accuracy: 0.9405\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88839 to 0.94048, saving model to models_img\\best_model.hdf5\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 139s 2s/step - loss: 0.2182 - accuracy: 0.9196 - val_loss: 0.2046 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.94048\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 141s 2s/step - loss: 0.2417 - accuracy: 0.9125 - val_loss: 0.2947 - val_accuracy: 0.8973\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.94048\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 138s 2s/step - loss: 0.1509 - accuracy: 0.9462 - val_loss: 0.1765 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.94048\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 194s 2s/step - loss: 0.1814 - accuracy: 0.9315 - val_loss: 0.1949 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.94048\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 222s 3s/step - loss: 0.1313 - accuracy: 0.9575 - val_loss: 0.1497 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.94048 to 0.95089, saving model to models_img\\best_model.hdf5\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 190s 2s/step - loss: 0.1541 - accuracy: 0.9471 - val_loss: 0.1017 - val_accuracy: 0.9658\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.95089 to 0.96577, saving model to models_img\\best_model.hdf5\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 147s 2s/step - loss: 0.1411 - accuracy: 0.9520 - val_loss: 0.0923 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.96577 to 0.97470, saving model to models_img\\best_model.hdf5\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 202s 2s/step - loss: 0.1130 - accuracy: 0.9599 - val_loss: 0.0956 - val_accuracy: 0.9673\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.97470\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 230s 3s/step - loss: 0.1194 - accuracy: 0.9677 - val_loss: 0.1628 - val_accuracy: 0.9598\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.97470\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 186s 2s/step - loss: 0.1145 - accuracy: 0.9580 - val_loss: 0.1035 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.97470\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 182s 2s/step - loss: 0.0882 - accuracy: 0.9699 - val_loss: 0.0812 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97470\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 240s 3s/step - loss: 0.1097 - accuracy: 0.9636 - val_loss: 0.1272 - val_accuracy: 0.9554\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97470\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 203s 2s/step - loss: 0.1010 - accuracy: 0.9680 - val_loss: 0.1271 - val_accuracy: 0.9613\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.97470\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 184s 2s/step - loss: 0.0957 - accuracy: 0.9674 - val_loss: 0.1120 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.97470\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 149s 2s/step - loss: 0.1302 - accuracy: 0.9558 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.97470\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 202s 2s/step - loss: 0.0808 - accuracy: 0.9732 - val_loss: 0.1627 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.97470\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 193s 2s/step - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.0924 - val_accuracy: 0.9702\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.97470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2afbaf53d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import ResNet101, DenseNet201 ,InceptionV3, DenseNet121\n",
    "from tensorflow.keras.layers import Input, Add, AveragePooling2D,  GlobalAveragePooling2D ,GlobalMaxPool2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def get_model(input_shape = (img_rows,img_cols,img_channels)):\n",
    "    #Get base model: ResNet50 or VGG16\n",
    "\n",
    "    base_model =  VGG19(weights='imagenet', include_top=False ,input_shape=input_shape)\n",
    "    #base_model =  ResNet101(weights='imagenet', include_top=False ,input_shape=input_shape)    \n",
    "    #base_model =  DenseNet201(weights='imagenet', include_top=False ,input_shape=input_shape)    \n",
    "    #base_model =  InceptionV3(weights='imagenet', include_top=False ,input_shape=input_shape)    \n",
    "    ## ChexNet\n",
    "    #base_model = DenseNet121( include_top=False, weights=None, input_shape=input_shape )\n",
    "    \n",
    "#     split_at = 7\n",
    "#     #print (len(base_model.layers))\n",
    "#     for layer in base_model.layers[:split_at]: layer.trainable = False\n",
    "#     for layer in base_model.layers[split_at:]: layer.trainable = True\n",
    "    #for layer in base_model.layers: layer.trainable = False\n",
    "        \n",
    "    # Get the output from the base model \n",
    "    #base_model_output = base_model.output\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(3, activation= 'softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    #model.load_weights('./densenet121_weights_tf.h5',by_name=True, skip_mismatch=True)\n",
    "    #model.load_weights('./brucechou1983_CheXNet_Keras_0.3.0_weights.h5',by_name=True, skip_mismatch=True)\n",
    "    #Finetuning\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "#     model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "#     # train the model on the new data for a few epochs\n",
    "#     model.fit_generator(training_set,  epochs=2, validation_data=validation_set, validation_steps=21)\n",
    "    \n",
    "        # let's visualize layer names and layer indices to see how many layers\n",
    "    # we should freeze:\n",
    "#     for i, layer in enumerate(model.layers):\n",
    "#        print(i, layer.name)\n",
    "    \n",
    "    # the first 248 layers and unfreeze the rest for inceptionv3: last 2 inception blocks\n",
    "    # the first 480 layers and unfreeze the rest for Densenet201: last dense block\n",
    "    # the first 312 layers and unfreeze the rest for resnet: last residual block\n",
    "    # the first 10 layers and unfreeze the rest for VGG19: last 2 conv block\n",
    "    split_at = 11\n",
    "    for layer in model.layers[:split_at]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[split_at:]:\n",
    "       layer.trainable = True\n",
    "    \n",
    "    \n",
    "    print (model.summary())\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generators\n",
    "#training_generator = DataGenerator('train')#, ablation=50)\n",
    "#validation_generator = DataGenerator('val')#, ablation=50)\n",
    "#print (training_generator)\n",
    "\n",
    "history = LossHistory()\n",
    "plot_data = {}\n",
    "filepath = 'models_img/best_model.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# fit\n",
    "model.fit_generator(training_set,  epochs=20, validation_data=validation_set, validation_steps=21, callbacks=[history, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[1.248996615409851, 0.3765992224216461, 0.24703018367290497, 0.21538293361663818, 0.22993548214435577, 0.16204464435577393, 0.1752534955739975, 0.1375114619731903, 0.13668470084667206, 0.1280728131532669, 0.12000250071287155, 0.12281256169080734, 0.10802589356899261, 0.09364466369152069, 0.09451119601726532, 0.09668582677841187, 0.09678496420383453, 0.11511107534170151, 0.07872350513935089, 0.08063217997550964]\n"
     ]
    }
   ],
   "source": [
    "print (len(history.losses))\n",
    "print (history.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 388 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#using the inbuilt imagegenerator\n",
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.math import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TEST_DATASET,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_set.reset() \n",
    "\n",
    "model = load_model('models_img/densenet201_Processed_3.hdf5')\n",
    "#model = load_model('models_img/vgg_Image_4.hdf5')\n",
    "Y_pred = model.predict_generator(test_set,388 // 32+1)\n",
    "y_pred = np.argmax(Y_pred,axis=-1)\n",
    "s=confusion_matrix(test_set.classes,y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2\n",
      " 2 1 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2]\n",
      "[[120   0   0]\n",
      " [  0 134   0]\n",
      " [  0  12 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    COVID-19       1.00      1.00      1.00       120\n",
      "      NORMAL       0.92      1.00      0.96       134\n",
      "       Viral       1.00      0.91      0.95       134\n",
      "\n",
      "    accuracy                           0.97       388\n",
      "   macro avg       0.97      0.97      0.97       388\n",
      "weighted avg       0.97      0.97      0.97       388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = data_cls\n",
    "print (test_set.classes)\n",
    "print (y_pred)\n",
    "c = classification_report(test_set.classes.tolist(),y_pred.tolist(),target_names=target_names)\n",
    "\n",
    "print (s)\n",
    "print (c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
